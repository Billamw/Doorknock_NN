{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 87) 20 87\n",
      "torch.Size([20, 87]) torch.Size([128, 87]) tensor([-636.7721, -601.3519, -598.6749, -602.1609, -600.3940, -596.8478,\n",
      "        -599.3187, -596.0143, -593.5973, -598.4329, -604.7067, -605.1030,\n",
      "        -601.0641, -596.8544, -591.7855, -596.7938, -600.1642, -595.5434,\n",
      "        -588.0572, -588.3832, -588.6238, -591.0091, -590.0090, -590.0597,\n",
      "        -590.2850, -587.3127, -591.7915, -512.9158, -413.2757, -406.4679,\n",
      "        -464.2597, -520.5369, -550.6030, -563.6320, -572.8664, -578.1237,\n",
      "        -585.2301, -586.1219, -591.0609, -597.7499, -578.3341, -489.0174,\n",
      "        -450.6488, -485.6049, -542.2120, -571.5487, -443.1389, -339.6843,\n",
      "        -344.1404, -421.1504, -491.7636, -546.1019, -495.2043, -453.1978,\n",
      "        -480.0365, -532.2638, -562.6099, -588.0812, -603.0444, -608.2986,\n",
      "        -610.0537, -608.2314, -607.9417, -609.4409, -571.5991, -406.2911,\n",
      "        -362.4875, -405.7906, -476.5858, -535.1148, -573.2919, -590.6755,\n",
      "        -596.3143, -602.1032, -602.1462, -599.7973, -601.1255, -602.8965,\n",
      "        -601.8792, -599.6461, -598.2524, -599.2198, -600.1486, -595.7242,\n",
      "        -596.1934, -602.5429, -629.9832])\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Definieren der Variablen\n",
    "source_dir = \"data/knocks\"\n",
    "\n",
    "# Durchlaufen des Ordners und Vorverarbeiten der Audiodateien\n",
    "data = []\n",
    "labels = []\n",
    "for filename in os.listdir(source_dir):\n",
    "    filepath = os.path.join(source_dir, filename)\n",
    "    \n",
    "    # Ignorieren von Verzeichnissen\n",
    "    if os.path.isdir(filepath):\n",
    "        continue\n",
    "    \n",
    "    # Audio laden\n",
    "    y, sr = librosa.load(filepath)\n",
    "\n",
    "    # Berechnen von MFCCs und Mel-Spektrogramm\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    print(mfcc.shape, len(mfcc), len(mfcc[0]))\n",
    "\n",
    "    tensor_mfcc = torch.from_numpy(mfcc).float()\n",
    "    tensor_mel = torch.from_numpy(mel).float()\n",
    "    print(tensor_mfcc.shape, tensor_mel.shape)\n",
    "    print(len( tensor_mfcc[0]))\n",
    "\n",
    "    # Daten und Label speichern\n",
    "    data.append([mfcc, mel])\n",
    "    labels.append(1 if filename.startswith(\"knock\") else 0)\n",
    "\n",
    "    break\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Pandas DataFrame erstellen\n",
    "# df = pd.DataFrame(data, columns=[\"mfcc\", \"mel\"])\n",
    "# df[\"label\"] = labels\n",
    "\n",
    "# df.to_csv(\"audio_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
