{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, mel_spectrograms, labels):\n",
    "        self.mel_spectrograms = mel_spectrograms\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mel_spectrograms)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.mel_spectrograms[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrograms = np.load(\"mel_spectrograms.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for filename in audio_filenames:\n",
    "    if \"knock\" in filename.split(\"_\")[0]:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teilen der Daten in Trainings-, Validierungs- und Testdatens√§tze\n",
    "train_dataset, val_dataset, test_dataset = split_dataset(mel_spectrograms, labels)\n",
    "\n",
    "# Normieren der Daten\n",
    "train_dataset = normalize_dataset(train_dataset)\n",
    "val_dataset = normalize_dataset(val_dataset)\n",
    "test_dataset = normalize_dataset(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, \"train_dataset.pt\")\n",
    "torch.save(val_dataset, \"val_dataset.pt\")\n",
    "torch.save(test_dataset, \"test_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
