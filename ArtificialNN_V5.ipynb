{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading and converting npy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mel = np.load('data/npy/data_mel.npy')\n",
    "labels_mel = np.load('data/npy/labels_mel.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Daten in Tensoren konvertieren\n",
    "data_tensor = torch.from_numpy(np.array(data_mel)).float()\n",
    "\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # Define the mean and standard deviation for normalization\n",
    "# mean_mel = data_tensor.mean()\n",
    "# std_mel = data_tensor.std()\n",
    "\n",
    "# np.save('data/npy/mean_mel.npy', mean_mel)\n",
    "# np.save('data/npy/std_mel.npy', std_mel)\n",
    "\n",
    "# # Create the transform\n",
    "# transform = transforms.Normalize(mean=mean_mel, std=std_mel)\n",
    "\n",
    "# # Reshape the data_tensor to have the shape (batch_size, channels, height, width)\n",
    "# data_tensor_for_normalisazion = data_tensor.view(-1, 1, 1, data_tensor.shape[1])\n",
    "# # Apply the transform to the data_tensor\n",
    "# normalized_data = transform(data_tensor_for_normalisazion)\n",
    "\n",
    "labels_tensor = torch.from_numpy(np.array(labels_mel))\n",
    "\n",
    "# Teilen der Daten in Trainings- und Testdatensätze\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_tensor, labels_tensor, test_size=0.2)\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "torch.save(X_train, 'data/pt/X_train.pt')\n",
    "torch.save(X_test, 'data/pt/X_test.pt')\n",
    "torch.save(y_train, 'data/pt/y_train.pt')\n",
    "torch.save(y_test, 'data/pt/y_test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load('data/pt/X_train.pt')\n",
    "X_test = torch.load('data/pt/X_test.pt')\n",
    "y_train = torch.load('data/pt/y_train.pt')\n",
    "y_test = torch.load('data/pt/y_test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining knn model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Erstes lineares Layer\n",
    "        self.fc1 = nn.Linear(22144, 5000)\n",
    "        # ReLU Aktivierungsfunktion\n",
    "        self.relu = nn.ReLU()\n",
    "        # Dropout-Layer mit Wahrscheinlichkeit 0.2\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        # Zweites lineares Layer\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        # ReLU Aktivierungsfunktion\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Drittes lineares Layer\n",
    "        self.fc3 = nn.Linear(1000, 250)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # Dropout-Layer mit Wahrscheinlichkeit 0.2\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        # Viertes lineares Layer\n",
    "        self.fc4 = nn.Linear(250, 10)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        # Fünftes lineares Layer\n",
    "        self.fc5 = nn.Linear(10, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellinstanz\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(22144, 5000),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(5000, 1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 250),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(250, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2 of sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(22144, 15000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(15000, 10000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10000, 5000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5000, 2500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(2500, 2000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(2000, 1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1000, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 1),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('data/models/KNNmodelV1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# add learning rate scheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1682853400707245, Prediction: 1.2929940223693848, Label: 1\n",
      "Epoch 2, Loss: 0.1674351692199707, Prediction: 1.2735421657562256, Label: 1\n",
      "Epoch 3, Loss: 0.16675874590873718, Prediction: 1.261552333831787, Label: 1\n",
      "Epoch 4, Loss: 0.1662050187587738, Prediction: 1.2607415914535522, Label: 1\n",
      "Epoch 5, Loss: 0.16576947271823883, Prediction: 1.26121187210083, Label: 1\n",
      "Epoch 6, Loss: 0.16540132462978363, Prediction: 1.253309726715088, Label: 1\n",
      "Epoch 7, Loss: 0.16503269970417023, Prediction: 1.2352243661880493, Label: 1\n",
      "Epoch 8, Loss: 0.16472068428993225, Prediction: 1.212985634803772, Label: 1\n",
      "Epoch 9, Loss: 0.16447614133358002, Prediction: 1.196418285369873, Label: 1\n",
      "Epoch 10, Loss: 0.1642206907272339, Prediction: 1.189307689666748, Label: 1\n",
      "Epoch 11, Loss: 0.1640198826789856, Prediction: 1.189310908317566, Label: 1\n",
      "Epoch 12, Loss: 0.1638403981924057, Prediction: 1.187508463859558, Label: 1\n",
      "Epoch 13, Loss: 0.16371409595012665, Prediction: 1.1775155067443848, Label: 1\n",
      "Epoch 14, Loss: 0.16341276466846466, Prediction: 1.1631773710250854, Label: 1\n",
      "Epoch 15, Loss: 0.16325019299983978, Prediction: 1.1540876626968384, Label: 1\n",
      "Epoch 16, Loss: 0.16303594410419464, Prediction: 1.153975248336792, Label: 1\n",
      "Epoch 17, Loss: 0.16274844110012054, Prediction: 1.154876708984375, Label: 1\n",
      "Epoch 18, Loss: 0.16242152452468872, Prediction: 1.1488852500915527, Label: 1\n",
      "Epoch 19, Loss: 0.1620766967535019, Prediction: 1.1351872682571411, Label: 1\n",
      "Epoch 20, Loss: 0.1618041843175888, Prediction: 1.1212677955627441, Label: 1\n",
      "Epoch 21, Loss: 0.16150270402431488, Prediction: 1.1170085668563843, Label: 1\n",
      "Epoch 22, Loss: 0.16119307279586792, Prediction: 1.1178886890411377, Label: 1\n",
      "Epoch 23, Loss: 0.16088783740997314, Prediction: 1.1132385730743408, Label: 1\n",
      "Epoch 24, Loss: 0.16059282422065735, Prediction: 1.09791100025177, Label: 1\n",
      "Epoch 25, Loss: 0.16033759713172913, Prediction: 1.0829771757125854, Label: 1\n",
      "Epoch 26, Loss: 0.1600726842880249, Prediction: 1.079044222831726, Label: 1\n",
      "Epoch 27, Loss: 0.15985718369483948, Prediction: 1.0785852670669556, Label: 1\n",
      "Epoch 28, Loss: 0.15958085656166077, Prediction: 1.0622241497039795, Label: 1\n",
      "Epoch 29, Loss: 0.15926790237426758, Prediction: 1.03126060962677, Label: 1\n",
      "Epoch 30, Loss: 0.15896430611610413, Prediction: 1.0302480459213257, Label: 1\n",
      "Epoch 31, Loss: 0.158734530210495, Prediction: 1.0219805240631104, Label: 1\n",
      "Epoch 32, Loss: 0.15888497233390808, Prediction: 0.9564992785453796, Label: 1\n",
      "Epoch 33, Loss: 0.15991857647895813, Prediction: 1.0766587257385254, Label: 1\n",
      "Epoch 34, Loss: 0.15812470018863678, Prediction: 0.988180935382843, Label: 1\n",
      "Epoch 35, Loss: 0.15905772149562836, Prediction: 0.9313437342643738, Label: 1\n",
      "Epoch 36, Loss: 0.1578330099582672, Prediction: 1.0260009765625, Label: 1\n",
      "Epoch 37, Loss: 0.15811143815517426, Prediction: 1.0456886291503906, Label: 1\n",
      "Epoch 38, Loss: 0.15731461346149445, Prediction: 0.969750702381134, Label: 1\n",
      "Epoch 39, Loss: 0.15748907625675201, Prediction: 0.9472025036811829, Label: 1\n",
      "Epoch 40, Loss: 0.1567240059375763, Prediction: 1.0083565711975098, Label: 1\n",
      "Epoch 41, Loss: 0.15687334537506104, Prediction: 1.0337679386138916, Label: 1\n",
      "Epoch 42, Loss: 0.156162828207016, Prediction: 0.9824824929237366, Label: 1\n",
      "Epoch 43, Loss: 0.1562831997871399, Prediction: 0.9612722992897034, Label: 1\n",
      "Epoch 44, Loss: 0.1556369662284851, Prediction: 1.0101860761642456, Label: 1\n",
      "Epoch 45, Loss: 0.1557014137506485, Prediction: 1.0350650548934937, Label: 1\n",
      "Epoch 46, Loss: 0.1551249623298645, Prediction: 0.9859300255775452, Label: 1\n",
      "Epoch 47, Loss: 0.15514500439167023, Prediction: 0.9515965580940247, Label: 1\n",
      "Epoch 48, Loss: 0.1546652466058731, Prediction: 0.9781847596168518, Label: 1\n",
      "Epoch 49, Loss: 0.1546618789434433, Prediction: 0.9954946637153625, Label: 1\n",
      "Epoch 50, Loss: 0.15424878895282745, Prediction: 0.9551776051521301, Label: 1\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    output = output.squeeze()  # Remove dimensions of size 1\n",
    "    loss = criterion(output, y_train.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}, Prediction: {output[0]}, Label: {y_train[0]}')\n",
    "    if loss.item() < 1-0.91:\n",
    "        print('break')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2 of training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3177614212036133 \t Prediction: 0.14113286137580872, 1.0\n",
      "Epoch 2, Loss: 0.3772405982017517 \t Prediction: 0.12729227542877197, 0.0\n",
      "Epoch 3, Loss: 0.235407754778862 \t Prediction: 0.12334516644477844, 0.0\n",
      "Epoch 4, Loss: 0.26235049962997437 \t Prediction: 0.14205844700336456, 0.0\n",
      "Epoch 5, Loss: 0.40755367279052734 \t Prediction: 0.14328402280807495, 1.0\n",
      "Epoch 6, Loss: 0.31707221269607544 \t Prediction: 0.1453307718038559, 0.0\n",
      "Epoch 7, Loss: 0.34748023748397827 \t Prediction: 0.1399935930967331, 0.0\n",
      "Epoch 8, Loss: 0.35070592164993286 \t Prediction: 0.1402902752161026, 1.0\n",
      "Epoch 9, Loss: 0.25719547271728516 \t Prediction: 0.1458253413438797, 0.0\n",
      "Epoch 10, Loss: 0.37623390555381775 \t Prediction: 0.14606483280658722, 1.0\n",
      "Epoch 11, Loss: 0.40726277232170105 \t Prediction: 0.14544226229190826, 1.0\n",
      "Epoch 12, Loss: 0.3475767970085144 \t Prediction: 0.14418278634548187, 0.0\n",
      "Epoch 13, Loss: 0.2590540051460266 \t Prediction: 0.14226843416690826, 1.0\n",
      "Epoch 14, Loss: 0.3180863857269287 \t Prediction: 0.14370089769363403, 1.0\n",
      "Epoch 15, Loss: 0.42785629630088806 \t Prediction: 0.14533403515815735, 1.0\n",
      "Epoch 16, Loss: 0.23061317205429077 \t Prediction: 0.14141316711902618, 0.0\n",
      "Epoch 17, Loss: 0.44295716285705566 \t Prediction: 0.14125333726406097, 1.0\n",
      "Epoch 18, Loss: 0.2920985817909241 \t Prediction: 0.14422795176506042, 0.0\n",
      "Epoch 19, Loss: 0.22927002608776093 \t Prediction: 0.14117471873760223, 0.0\n",
      "Epoch 20, Loss: 0.40805768966674805 \t Prediction: 0.1435801386833191, 0.0\n",
      "Epoch 21, Loss: 0.40681561827659607 \t Prediction: 0.14517265558242798, 0.0\n",
      "Epoch 22, Loss: 0.28644412755966187 \t Prediction: 0.1452687382698059, 0.0\n",
      "Epoch 23, Loss: 0.3215647339820862 \t Prediction: 0.14488282799720764, 0.0\n",
      "Epoch 24, Loss: 0.4985489845275879 \t Prediction: 0.1455330103635788, 0.0\n",
      "Epoch 25, Loss: 0.2287474125623703 \t Prediction: 0.14345785975456238, 1.0\n",
      "Epoch 26, Loss: 0.3181990683078766 \t Prediction: 0.1417582631111145, 1.0\n",
      "Epoch 27, Loss: 0.28850945830345154 \t Prediction: 0.10394114255905151, 0.0\n",
      "Epoch 28, Loss: 0.4371297359466553 \t Prediction: 0.1453305333852768, 0.0\n",
      "Epoch 29, Loss: 0.3295302093029022 \t Prediction: 0.14189019799232483, 0.0\n",
      "Epoch 30, Loss: 0.28830498456954956 \t Prediction: 0.14201653003692627, 0.0\n",
      "Epoch 31, Loss: 0.3167765140533447 \t Prediction: 0.14624910056591034, 0.0\n",
      "Epoch 32, Loss: 0.28804314136505127 \t Prediction: 0.1428387314081192, 1.0\n",
      "Epoch 33, Loss: 0.3487042188644409 \t Prediction: 0.1422993540763855, 0.0\n",
      "Epoch 34, Loss: 0.20336954295635223 \t Prediction: 0.14481352269649506, 1.0\n",
      "Epoch 35, Loss: 0.43735361099243164 \t Prediction: 0.14294348657131195, 1.0\n",
      "Epoch 36, Loss: 0.2921411097049713 \t Prediction: 0.14236409962177277, 0.0\n",
      "Epoch 37, Loss: 0.34768983721733093 \t Prediction: 0.14173385500907898, 1.0\n",
      "Epoch 38, Loss: 0.25916704535484314 \t Prediction: 0.14174619317054749, 1.0\n",
      "Epoch 39, Loss: 0.49756282567977905 \t Prediction: 0.14046111702919006, 1.0\n",
      "Epoch 40, Loss: 0.3513718545436859 \t Prediction: 0.145355686545372, 1.0\n",
      "Epoch 41, Loss: 0.3778497576713562 \t Prediction: 0.14089718461036682, 1.0\n",
      "Epoch 42, Loss: 0.318390429019928 \t Prediction: 0.1425396054983139, 1.0\n",
      "Epoch 43, Loss: 0.31592655181884766 \t Prediction: 0.14289408922195435, 1.0\n",
      "Epoch 44, Loss: 0.4372507929801941 \t Prediction: 0.1457565724849701, 0.0\n",
      "Epoch 45, Loss: 0.20072349905967712 \t Prediction: 0.14014244079589844, 0.0\n",
      "Epoch 46, Loss: 0.23063597083091736 \t Prediction: 0.1429031640291214, 0.0\n",
      "Epoch 47, Loss: 0.4069092869758606 \t Prediction: 0.13814176619052887, 0.0\n",
      "Epoch 48, Loss: 0.20953986048698425 \t Prediction: 0.11526963114738464, 0.0\n",
      "Epoch 49, Loss: 0.3524542450904846 \t Prediction: 0.14231067895889282, 1.0\n",
      "Epoch 50, Loss: 0.17214751243591309 \t Prediction: 0.14134763181209564, 0.0\n",
      "Epoch 51, Loss: 0.2882084250450134 \t Prediction: 0.14667396247386932, 0.0\n",
      "Epoch 52, Loss: 0.2980617880821228 \t Prediction: 0.1407357007265091, 0.0\n",
      "Epoch 53, Loss: 0.3767361044883728 \t Prediction: 0.14274662733078003, 1.0\n",
      "Epoch 54, Loss: 0.44218286871910095 \t Prediction: 0.1449616253376007, 1.0\n",
      "Epoch 55, Loss: 0.4674902856349945 \t Prediction: 0.14038251340389252, 1.0\n",
      "Epoch 56, Loss: 0.478532075881958 \t Prediction: 0.14101818203926086, 1.0\n",
      "Epoch 57, Loss: 0.3170892596244812 \t Prediction: 0.14153599739074707, 0.0\n",
      "Epoch 58, Loss: 0.2594839334487915 \t Prediction: 0.1436990201473236, 1.0\n",
      "Epoch 59, Loss: 0.40786463022232056 \t Prediction: 0.1430342197418213, 1.0\n",
      "Epoch 60, Loss: 0.3466683328151703 \t Prediction: 0.1417616903781891, 0.0\n",
      "Epoch 61, Loss: 0.3243299722671509 \t Prediction: 0.14152689278125763, 0.0\n",
      "Epoch 62, Loss: 0.6171424388885498 \t Prediction: 0.14438436925411224, 1.0\n",
      "Epoch 63, Loss: 0.3769925534725189 \t Prediction: 0.14304879307746887, 1.0\n",
      "Epoch 64, Loss: 0.3165440559387207 \t Prediction: 0.1419590711593628, 1.0\n",
      "Epoch 65, Loss: 0.377533882856369 \t Prediction: 0.1402926743030548, 1.0\n",
      "Epoch 66, Loss: 0.290928453207016 \t Prediction: 0.14347447454929352, 0.0\n",
      "Epoch 67, Loss: 0.35261672735214233 \t Prediction: 0.14485162496566772, 0.0\n",
      "Epoch 68, Loss: 0.3769007623195648 \t Prediction: 0.14288419485092163, 1.0\n",
      "Epoch 69, Loss: 0.3473380506038666 \t Prediction: 0.14181554317474365, 1.0\n",
      "Epoch 70, Loss: 0.3174557089805603 \t Prediction: 0.1421888768672943, 1.0\n",
      "Epoch 71, Loss: 0.37862151861190796 \t Prediction: 0.14211829006671906, 0.0\n",
      "Epoch 72, Loss: 0.2887122631072998 \t Prediction: 0.14258253574371338, 0.0\n",
      "Epoch 73, Loss: 0.31923389434814453 \t Prediction: 0.14220885932445526, 0.0\n",
      "Epoch 74, Loss: 0.4676923453807831 \t Prediction: 0.14122647047042847, 1.0\n",
      "Epoch 75, Loss: 0.2578234076499939 \t Prediction: 0.1407058835029602, 1.0\n",
      "Epoch 76, Loss: 0.43671727180480957 \t Prediction: 0.14313271641731262, 0.0\n",
      "Epoch 77, Loss: 0.3168348968029022 \t Prediction: 0.14256562292575836, 1.0\n",
      "Epoch 78, Loss: 0.34737610816955566 \t Prediction: 0.1461132913827896, 1.0\n",
      "Epoch 79, Loss: 0.31683093309402466 \t Prediction: 0.14307035505771637, 0.0\n",
      "Epoch 80, Loss: 0.258771687746048 \t Prediction: 0.13924357295036316, 0.0\n",
      "Epoch 81, Loss: 0.4077877700328827 \t Prediction: 0.10544683039188385, 0.0\n",
      "Epoch 82, Loss: 0.3470669388771057 \t Prediction: 0.13903042674064636, 0.0\n",
      "Epoch 83, Loss: 0.3179682493209839 \t Prediction: 0.14385759830474854, 1.0\n",
      "Epoch 84, Loss: 0.2910674810409546 \t Prediction: 0.14259834587574005, 1.0\n",
      "Epoch 85, Loss: 0.32262107729911804 \t Prediction: 0.2574861943721771, 0.0\n",
      "Epoch 86, Loss: 0.31701263785362244 \t Prediction: 0.14269523322582245, 1.0\n",
      "Epoch 87, Loss: 0.16759121417999268 \t Prediction: 0.14446711540222168, 1.0\n",
      "Epoch 88, Loss: 0.3188014626502991 \t Prediction: 0.1411621868610382, 1.0\n",
      "Epoch 89, Loss: 0.3195270299911499 \t Prediction: 0.14257697761058807, 0.0\n",
      "Epoch 90, Loss: 0.43644779920578003 \t Prediction: 0.1427793800830841, 0.0\n",
      "Epoch 91, Loss: 0.16856470704078674 \t Prediction: 0.07518332451581955, 0.0\n",
      "Epoch 92, Loss: 0.4962337017059326 \t Prediction: 0.14071600139141083, 1.0\n",
      "Epoch 93, Loss: 0.37813982367515564 \t Prediction: 0.1431015580892563, 1.0\n",
      "Epoch 94, Loss: 0.37728604674339294 \t Prediction: 0.14140242338180542, 0.0\n",
      "Epoch 95, Loss: 0.2900357246398926 \t Prediction: 0.13885903358459473, 0.0\n",
      "Epoch 96, Loss: 0.4972112774848938 \t Prediction: 0.14399488270282745, 1.0\n",
      "Epoch 97, Loss: 0.3536378741264343 \t Prediction: 0.14362479746341705, 1.0\n",
      "Epoch 98, Loss: 0.28843986988067627 \t Prediction: 0.16458475589752197, 0.0\n",
      "Epoch 99, Loss: 0.3769668936729431 \t Prediction: 0.1448381245136261, 0.0\n",
      "Epoch 100, Loss: 0.3770124614238739 \t Prediction: 0.14437329769134521, 1.0\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a DataLoader to handle batching of the training data\n",
    "batch_size = 32\n",
    "train_data = torch.utils.data.TensorDataset(X_train, y_train.float())\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X)\n",
    "        output = output.squeeze()  # Remove dimensions of size 1\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()} \\t Prediction: {output[0]}, {batch_y[0]}')\n",
    "    if loss.item() < 1-0.91:\n",
    "        print('break')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 1.0065126419067383, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 1.0110076665878296, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 1.0109965801239014, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.9916501641273499, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.9598390460014343, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.9152770638465881, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.6705998182296753, True Label: 1\n",
      "pred: 0.9357160925865173, True Label: 1\n",
      "pred: 0.7933692336082458, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.964231550693512, True Label: 1\n",
      "pred: 0.9564527869224548, True Label: 1\n",
      "pred: 0.9506884217262268, True Label: 1\n",
      "pred: 0.9345863461494446, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 1\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.9328473210334778, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 0\n",
      "pred: 0.27173441648483276, True Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test data\n",
    "for i in range(len(X_test)):\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test[i])\n",
    "        output = output.squeeze()\n",
    "        est_loss = criterion(output, y_test[i].float())\n",
    "        print(f\"pred: {output.item()}, True Label: {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'data/models/KNNmodelV2-2.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
